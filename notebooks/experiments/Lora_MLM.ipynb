{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../../src')\n",
    "\n",
    "import torch\n",
    "import evaluate\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    AutoModelForMaskedLM\n",
    ")\n",
    "\n",
    "from TextProcessor import TextProcessor\n",
    "from DatasetProcessor import DatasetProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current tracking uri: http://mlflow:5000\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "tracking_uri = mlflow.get_tracking_uri()\n",
    "print(\"Current tracking uri: {}\".format(tracking_uri))\n",
    "\n",
    "os.environ[\"MLFLOW_EXPERIMENT_NAME\"] = \"NER\"\n",
    "# os.environ[\"HF_MLFLOW_LOG_ARTIFACTS\"] = \"True\"\n",
    "\n",
    "# os.environ[\"MLFLOW_FLATTEN_PARAMS\"] = \"True\"\n",
    "\n",
    "# os.environ[\"MLFLOW_TRACKING_URI\"] = tracking_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../dataset/RuMedPrimeData.tsv'\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, sep='\\t')\n",
    "df = df[['symptoms', 'anamnesis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15250"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = []\n",
    "texts.extend(df['symptoms'].tolist())\n",
    "texts.extend(df['anamnesis'].tolist())\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 14487\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 763\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_dict({'text': texts})\n",
    "dataset = dataset.train_test_split(test_size=0.05)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"alexyalunin/RuBioRoBERTa\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d98016f684418a953db2fcc0ffdd14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a144953c8b8947e8a5128df8eb70be1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/763 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 14487\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 763\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    result = tokenizer(examples[\"text\"],\n",
    "                    #    truncation=True, max_length=512, padding=True\n",
    "                       )\n",
    "    if tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    return result\n",
    "\n",
    "\n",
    "# Use batched=True to activate fast multithreading!\n",
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_function, batched=True, remove_columns=[\"text\"]\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 512\n",
    "\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    # Compute length of concatenated texts\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the last chunk if it's smaller than chunk_size\n",
    "    total_length = (total_length // chunk_size) * chunk_size\n",
    "    # Split by chunks of max_len\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # Create a new labels column\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676b68113e0349e597833835027210fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4432267f7a14221be81038d8194d486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/763 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 2453\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 117\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> <s> на перебои в работе сердца, од<mask><mask>анного характера при<mask>, общую слабость.</s><s> Жал<mask> на ноющие боли внизу живота в течение 5-ти дней. УЗИ ОМТ от<mask>ДАТА<mask>: Множественная миома матки малых размеров, субму<mask>озынй рост<mask><mask> узлов. Наличие жидкостных образований в правом яичнике<mask>19.7 и 23<mask>9 мм).</s><s> Считает себя больной с *ДАТА<mask> (55 лет),<mask> после перенес<mask> стресса появилось дрожание правой руке. Изменился почерк.</s><s> больна в течении года.<mask>рт: единичные очаги дисциркуляции киста эпифиза.</s><s> Симптомы<mask><mask>ивируют 7 дней<mask> без<mask> с чем-либо.Ела суши. Не обследована</s><s> больна винк<mask>го времени( привела родственница) стала странно себя вести. мрт: нейродегенерация церебр<mask> имкроангиопат<mask><mask> участки г растворилсяоз<mask> трансформации глубинных отделов правой гемисферы конв<mask><mask>альных дополнение теменных долей с обеих сторон в исходе перенесенных онм<mask>( сосудистых повреждений). мр-карт<mask> малого ишемического онмк в бассене правой см Ней подострая стадия.</s><s> прежние<mask> пОВТОРНЫЙ ПРИЕМ ПОСЛЕ ДООБСЛЕДОВА<mask></s><s> * Суставной синдром с<mask>ДАТА*- боли в к/с (без отека и гиперемии<mask> лечение местно<mask>11<mask><mask>ло<mask>енцию свечи, с временным полож<mask><mask>. * Боли в левом плечевом<mask>е после травмы (пад светлый на него) *ДАТА* - лечение: массаж, ФТЛ<mask> НПВС в/<mask> (наз<mask> не помнит),<mask> того момент отмечает лишь периодически боли<mask> левом<mask>евом суставеейн БМах в пр плечевом суставе с *ДАТА* - после переохлаждения - ограничение подъема плеча до гориз уровня, заведения пр плеча за спину, конс неврологом - принимала мелоксикам в/м № 7, кортидокалм, комбил<mask><mask>, эффект от лечения временный - через 2 недели после окончания<mask> вновь возобновление болей - в/<mask> самостоятельно применяла<mask>лофенак Уча<mask> временным положительным эффектом, после курса мелоксикама 15 мг 15 дней - боли<mask> плечевых суставах не беспокоят Семейный ан'\n",
      "\n",
      "'>>> амнез: у брата Болезнь Б выехалитерева, у бабушки<mask> Ш<mask>. Работ<mask> - труд сидячий. Пс<mask>азом<mask> страдает. Хронические заболевания: ХитБ, хр. пиелонефрит. Травмы новый операции, низкоэнергетические перелом<mask><mask> аппендэктомия. Аллергологический анамнез<mask><mask> папаверин, магнезия<mask> сыпь, зуд<mask> диарея. Регулярно принимает<mask> лозартан Н 12.5, лоратадин.</s><s> ск<mask><mask> мыш<mask><mask>, выраженная<mask> в шейном отд. поз-ка,антин объем дивженйи в шейном отд., иррадиация<mask> плечи и правую руку Психоэмоц. напряжением (трев<mask>ность, подавленный<mask> настроение) \"зачем просыпатья с утра\"? Утром отмечает выраженную боль в зат<mask>ной области.</s><s> 26 лет<mask> Конс<mask>ция по потеклатра<mask><mask>.</s><s> Диагноз<mask>хиальнойиллмы установлен в *<mask>ТА*. С *ДАТА*. по *ДА<mask>*. регулярно<mask><mask>ликсотидом 250 мкг 1 раз в день<mask><mask>одуалом по<mask>. С *ДА<mask>*. проживала<mask> *ГО<mask>Д* и необходимость в прим лекарств отпала объявляет С *ДАТА* вернулась<mask> *<mask>*. Ухудшение<mask>ствия<mask> 2 недели<mask>. Стало закладыватьатемат в утрен<mask> часы. Лечилась беродуалом 30<mask> через небулайз<mask> - 2 раза в<mask>, эффект был    \n",
      ", \"хватало\" на определенное время, дополнительно ингаляторами не пользовалась<mask> Аллергия на цветение березы, шерсть животных в виде бронхоспазма. У мамы БА. Проф. вредностей не имеет. Не курит.</s><s> Боли в левой подвздошной области. Метеоризм. Стул<mask>оформленный до 4 раз в сутки (только в дневное<mask>).</s><s><mask> фоне проведенного лечения значительное улучшение</s><s> М<mask>ные с подросткового возраста с незначительными задержками по 7-10 дней или через 2<mask>. Всегда обильные. Роды<mask><mask> в<mask> лет, с этого времени00ные стали более стабильными. Предохранялась презевратив<mask>, беременности больше не было. С *ДАТА* очередные месячные в срок<mask> но скудные темно-коричневого цвета без сгустков. В *<mask><mask>*<mask>ных нет-'\n"
     ]
    }
   ],
   "source": [
    "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
    "for sample in samples:\n",
    "    _ = sample.pop(\"word_ids\")\n",
    "\n",
    "for chunk in data_collator(samples)[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "wwm_probability = 0.2\n",
    "\n",
    "\n",
    "def whole_word_masking_data_collator(features):\n",
    "    for feature in features:\n",
    "        word_ids = feature.pop(\"word_ids\")\n",
    "\n",
    "        # Create a map between words and corresponding token indices\n",
    "        mapping = collections.defaultdict(list)\n",
    "        current_word_index = -1\n",
    "        current_word = None\n",
    "        for idx, word_id in enumerate(word_ids):\n",
    "            if word_id is not None:\n",
    "                if word_id != current_word:\n",
    "                    current_word = word_id\n",
    "                    current_word_index += 1\n",
    "                mapping[current_word_index].append(idx)\n",
    "\n",
    "        # Randomly mask words\n",
    "        mask = np.random.binomial(1, wwm_probability, (len(mapping),))\n",
    "        input_ids = feature[\"input_ids\"]\n",
    "        labels = feature[\"labels\"]\n",
    "        new_labels = [-100] * len(labels)\n",
    "        for word_id in np.where(mask)[0]:\n",
    "            word_id = word_id.item()\n",
    "            for idx in mapping[word_id]:\n",
    "                new_labels[idx] = labels[idx]\n",
    "                input_ids[idx] = tokenizer.mask_token_id\n",
    "        feature[\"labels\"] = new_labels\n",
    "\n",
    "    return data_collator(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> <s> на перебои<mask><mask><mask>, одышку<mask><mask> характера<mask> ФН, общую слабость<mask></s><s><mask><mask> на ноющие боли внизу живота в течение<mask>-ти<mask>. УЗИ ОМТ от *ДАТА*: Множественная<mask>ома<mask>ки малых размеров,<mask><mask><mask><mask><mask><mask> рост<mask> из узлов. Наличие жидкостных образований<mask> правом яич<mask> (19.<mask> и 23.9<mask>).</s><s> Считает<mask> больной<mask><mask>ДАТА* (55 лет), когда после<mask><mask><mask><mask> дрожание<mask> руке<mask><mask>ился<mask>.</s><s><mask> в<mask><mask> = мрт: единичные<mask>аги дис<mask>куляции киста<mask>ифиза.</s><s> Симптомы рецидивируют<mask><mask>, Реж связи<mask> чем<mask>либо.Ела суши. Не обследована</s><s> больна в<mask><mask><mask> времени<mask> привела<mask><mask>)<mask> странно себя вести<mask> мрт<mask><mask>родег<mask>ция цер<mask>ральная<mask><mask><mask><mask><mask><mask><mask>. участки<mask><mask><mask><mask> трансформации глубинных отделов правой гемисферы конвекситальных отделов<mask><mask> долей с обеих сторон<mask> исходе перенесенных<mask><mask><mask><mask><mask><mask> повреждений). мр-картина малого насчитшемического онмк в бассене правой сма<mask><mask><mask> стадия<mask></s><s> прежние.<mask><mask><mask><mask><mask><mask> ПРИ<mask> ПОСЛЕ ДООБСЛЕДОВАНИЯ</s><s> *<mask><mask><mask> синдром с *ДАТА*- боли<mask><mask><mask>с праздником<mask> отека и гиперемии), лечение местно 911, диклофен<mask> свечи, с временным положительным эффектом. * Боли в левом<mask><mask> суставе после травмы (<mask><mask> на него)<mask>ДАТА* - лечение:<mask><mask><mask><mask><mask>,<mask><mask><mask>/м (<mask><mask> не помнит),<mask> Денег момент отмечает лишь<mask><mask> в левом плеч<mask> суставе *<mask><mask> в<mask> плечлич суставе с *ДАТА<mask> - после переохлаждения - ограничение<mask> плеча произвол гориз уровня,<mask> пр плеча<mask> спину<mask> конс невр<mask> - принимала<mask>оксикам<mask><mask><mask> энергетики 7, мидокалм<mask><mask><mask><mask><mask>, эффект от лечения<mask> - через 2 недели после небесные<mask> вновь<mask><mask> болей<mask> в/<mask> самостоятельно<mask><mask><mask><mask><mask><mask><mask> - с временным положительным<mask>, после курса мелоксикама 15 мг<mask> дней - боли в<mask>евых суставах не беспок<mask> Семейный<mask>'\n",
      "\n",
      "'>>> амнез<mask> у<mask> Болезнь Бехтерева, у бабушки перелом ШБ<mask><mask><mask> - труд<mask><mask><mask>.<mask><mask><mask><mask><mask> страдает<mask><mask><mask><mask> заболевания<mask> ГБ, хр<mask> пиелонефрит. Травмы, дуэли, низкоэнергетические переломы<mask><mask><mask><mask><mask><mask><mask>.<mask><mask><mask><mask><mask><mask><mask>: на папаверин, магнез<mask> - сыпь,<mask><mask> диарея. Регулярно<mask>:<mask><mask><mask> Н 12.<mask>,<mask><mask><mask><mask><mask></s><s><mask> чистую в<mask><mask> шеи, выраженная боль в шейном<mask>. поз-<mask>, ограничен<mask> дивженйи в<mask><mask><mask><mask><mask> ир<mask>иация<mask> плечи и<mask><mask><mask>оэмоц. напряжением<mask>трев<mask>ность<mask> подавленный фон настроение) \"зачем просыпатья с утра\"? Утром<mask> выраженную<mask> в затылоч<mask> области.</s><s> 26 лет. Консульта<mask> по<mask>трацепции.</s><s><mask><mask><mask> бронхиальной<mask><mask><mask> в<mask>ДАТА*.<mask> *ДАТА*. по *ДАТА*. регулярно<mask> фликсотидом<mask> мк<mask><mask><mask> в<mask><mask><mask><mask><mask> по потребности<mask> С *<mask><mask><mask><mask><mask><mask><mask> *<mask><mask><mask><mask><mask> необходимость в прим лекарств отпала. С<mask><mask>ТА* вернулась<mask><mask>Город<mask>. Ух<mask>ение<mask><mask> примерно 2 недели назад<mask> Стало закладывать грудь в утренние часы. Лечилась беродуалом 30<mask> через<mask><mask><mask><mask><mask><mask> раза в день<mask> эффект был<mask><mask> \"хватало\" на определенное время,<mask> ингаля членам не голосов<mask> Аллергия<mask><mask><mask> березы<mask><mask> животных в виде бронх отовсюдуазма. У мамы БА. Проф. вредностей<mask> имеет<mask> Не курит.</s><s> Боли в левой<mask>здошной области. Метеоризм.<mask>ул неоформленный до 4<mask> в<mask> (<mask> в дневное время<mask></s><s><mask> фоне проведенного лечения<mask> улучшение</s><s> Месячные с<mask><mask> возраста<mask> незначительными задержками<mask> 7<mask>10 дней или через<mask> недели. Всегда<mask><mask>. Роды - 1 в<mask><mask>, с<mask> времени месячные<mask> более<mask><mask><mask> Предохранялась презевративами,<mask><mask><mask> было<mask> С<mask>ДАТА* очередные месячные в срок, размещения скудные<mask><mask>коричневого<mask><mask> сгустков<mask><mask> *<mask>ТА<mask> месячных нет<mask>'\n"
     ]
    }
   ],
   "source": [
    "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
    "batch = whole_word_masking_data_collator(samples)\n",
    "\n",
    "for chunk in batch[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at alexyalunin/RuBioRoBERTa and are newly initialized: ['lm_head.decoder.bias', 'lm_head.decoder.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "class LoRALayer(nn.Module):\n",
    "    \"\"\"Wraps a linear layer with LoRA-like adapter. Wraps an existing OPT linear layer\"\"\"\n",
    "    def __init__(self, module: nn.Linear, rank: int):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "        self.adapter = nn.Sequential(\n",
    "            nn.Linear(module.in_features, rank, bias=False),\n",
    "            nn.Linear(rank, module.out_features, bias=False)\n",
    "        )\n",
    "        nn.init.kaiming_uniform_(self.adapter[0].weight, a=5 ** 0.5)\n",
    "        nn.init.zeros_(self.adapter[1].weight)\n",
    "\n",
    "        self.adapter.to(module.weight.device)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Apply self.module and LoRA adapter, return the sum (base module outputs + adapter outputs)\n",
    "        return self.module(input) + self.adapter(input)\n",
    "    \n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map={'': torch.cuda.current_device()},\n",
    "    cache_dir='.cache',\n",
    "    )\n",
    "\n",
    "for param in model.roberta.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "lora_rank = 128\n",
    "for name, module in model.roberta.named_modules():\n",
    "    if 'RobertaSelfAttention' in repr(type(module)):\n",
    "        module.query = LoRALayer(module.query, rank=lora_rank)\n",
    "        module.key = LoRALayer(module.key, rank=lora_rank)\n",
    "        module.value = LoRALayer(module.value, rank=lora_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knaumenko/.conda/envs/NER/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4620' max='4620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4620/4620 1:31:51, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.277700</td>\n",
       "      <td>1.243954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.915200</td>\n",
       "      <td>1.158979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.006800</td>\n",
       "      <td>1.041717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.049800</td>\n",
       "      <td>1.031428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.038100</td>\n",
       "      <td>1.038320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.056800</td>\n",
       "      <td>1.014725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.147700</td>\n",
       "      <td>0.984178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.060400</td>\n",
       "      <td>0.989031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.136800</td>\n",
       "      <td>0.989673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.072000</td>\n",
       "      <td>0.960911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.767900</td>\n",
       "      <td>0.975520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.034600</td>\n",
       "      <td>0.960248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.799000</td>\n",
       "      <td>0.965903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.801100</td>\n",
       "      <td>0.932458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.775500</td>\n",
       "      <td>0.901501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.775900</td>\n",
       "      <td>0.941793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.543500</td>\n",
       "      <td>0.926906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.847300</td>\n",
       "      <td>0.932331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.592500</td>\n",
       "      <td>0.863206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.997900</td>\n",
       "      <td>0.876293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.750800</td>\n",
       "      <td>0.893949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.660100</td>\n",
       "      <td>0.876753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.684500</td>\n",
       "      <td>0.863426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.867200</td>\n",
       "      <td>0.862097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.081500</td>\n",
       "      <td>0.878912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.932800</td>\n",
       "      <td>0.863616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.804700</td>\n",
       "      <td>0.869789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.732600</td>\n",
       "      <td>0.867793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.078700</td>\n",
       "      <td>0.844312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.725500</td>\n",
       "      <td>0.861327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cur_run_id = 2\n",
    "num_train_epochs = 30\n",
    "batch_size = 16\n",
    "\n",
    "name = \"RuBioRoBERTa-LoRA-MLM\"\n",
    "run_name = f'{name}-{cur_run_id:02}'\n",
    "output_dir = f'./logs/{run_name}'\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-4,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    weight_decay=0.01,\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=1,\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"mlflow\",\n",
    "    run_name=run_name\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = f'../../models/{run_name}.pt'\n",
    "torch.save(model, path_to_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
