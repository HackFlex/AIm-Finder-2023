{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset conll2003 (/home/kostia/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7137eb2d7df74e34b5dd588bb0e4bc87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "    num_rows: 14041\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 0, 7, 0, 0, 0, 7, 0, 0], [1, 2], [5, 0]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train']['ner_tags'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'],\n",
       " ['Peter', 'Blackburn'],\n",
       " ['BRUSSELS', '1996-08-22']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train']['tokens'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0][\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0, 7, 0, 0, 0, 7, 0, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0][\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_feature = raw_datasets[\"train\"].features[\"ner_tags\"]\n",
    "ner_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = ner_feature.feature.names\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU    rejects German call to boycott British lamb . \n",
      "B-ORG O       B-MISC O    O  O       B-MISC  O    O \n"
     ]
    }
   ],
   "source": [
    "words = raw_datasets[\"train\"][0][\"tokens\"]\n",
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = label_names[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(line1)\n",
    "print(line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"viktoroo/sberbank-rubert-base-collection3\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"viktoroo/sberbank-rubert-base-collection3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Рост 170 см.Вес 100,0 кг.ИМТ 34,60 кг/м2.Температура тела: 36,6 °C.  Правильно ориентирована в пространстве, собственной личности и времени: да . Питание: повышенное. Катаральные явления: нет. Кожа: обычной окраски, влажная. Видимые слизистые нормальной окраски.  Над легкими дыхание: жесткое. Хрипы: , единичные рассеянные сухие хрипы над всей поверхностью легких, застойные хрипы в н/отделах легких. ЧДД: 19 в мин , сатурация 96% на воздухе в покое.  Органы кровообращения: Пульс: 78 в мин, ритмичный.АД, мм рт.ст.: 160 / 100.  Органы пищеварения: Живот при пальпации: мягкий, не вздут, участвует в акте дыхания, чувствительный при пальпации в надлобковой области. Печень: не увеличена .Селезенка: не увеличена .Симптомы раздражения брюшины: нет .Отеки: пастозность стоп и голеней. Стул: оформленный( был сегодня утром), газы отходят. Патологические примеси в кале: нет .  Симптом поколачивания отрицательный с обеих сторон. Мочеиспускание: болезненное, учащенное, диурез достаточный ( со слов больной).  Гемоглобин -124, Лейкоциты – 7.8, Тром-138.Рент ОГК - очаговых и инфильтративных изменений нет. Усилен легочный рисунок в н/о. Сердце расширено влево. ЭКГ -ритм синусовый, ПБПНПГ, ишемических изменений не выявлено. КТ головного мозга- острой патологии нет.'\n",
    "tokens = tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 5440, 13262, 4621, 126, 7399, 2569, 121, 144, 7609, 126, 1205, 380, 5356, 121, 3843, 7609, 197, 65065, 126, 10680, 4692, 162, 4835, 121, 180, 255, 467, 126, 5761, 89217, 113, 11835, 121, 8277, 378, 9115, 107, 1866, 162, 789, 126, 21531, 162, 64094, 126, 63691, 17733, 15827, 162, 1177, 126, 8224, 162, 3924, 378, 63965, 121, 112142, 126, 99953, 33400, 5284, 8501, 378, 63965, 126, 1415, 54557, 10575, 162, 62376, 126, 38529, 162, 121, 79349, 31534, 767, 38706, 38529, 1415, 780, 378, 35560, 18621, 121, 18267, 18432, 376, 38529, 113, 108, 197, 100698, 18621, 126, 127, 23736, 162, 855, 113, 8970, 121, 798, 2483, 977, 11732, 210, 660, 8209, 113, 19980, 126, 7528, 74763, 162, 44686, 162, 11039, 113, 8970, 121, 35104, 12866, 378, 126, 1575, 121, 5483, 70789, 126, 811, 126, 162, 12016, 197, 2569, 126, 7528, 87325, 162, 15439, 711, 3254, 739, 801, 162, 5021, 12020, 121, 672, 51113, 380, 121, 19192, 113, 53330, 26518, 121, 98010, 378, 711, 3254, 739, 801, 113, 1415, 27259, 6180, 378, 1551, 126, 20740, 162, 672, 51392, 126, 75606, 77600, 162, 672, 51392, 126, 30303, 48460, 8797, 16805, 162, 1177, 126, 99825, 378, 162, 73868, 32968, 753, 27276, 107, 33294, 691, 378, 126, 13494, 162, 74955, 667, 378, 160, 905, 1806, 5111, 158, 121, 63360, 79791, 126, 29822, 2398, 100726, 113, 47350, 162, 1177, 126, 75546, 3427, 662, 31568, 5767, 14555, 378, 110, 10822, 4072, 126, 96508, 863, 162, 91376, 121, 1173, 20788, 121, 1029, 10156, 396, 16470, 667, 378, 160, 689, 5386, 11065, 378, 158, 126, 104744, 2823, 133, 23230, 121, 987, 24579, 375, 75206, 204, 182, 126, 178, 121, 44475, 133, 27067, 126, 25281, 1836, 385, 133, 57008, 14927, 107, 3894, 75278, 1011, 4461, 28608, 1177, 126, 115297, 30545, 12866, 378, 23484, 113, 108, 197, 104, 126, 4721, 65867, 375, 25355, 126, 1267, 393, 133, 27808, 96587, 117179, 378, 121, 117, 395, 388, 379, 118726, 121, 107, 78266, 1874, 28608, 672, 30214, 126, 114, 380, 23344, 9754, 133, 4462, 378, 61565, 1177, 126, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'рост',\n",
       " '170',\n",
       " 'см',\n",
       " '.',\n",
       " 'вес',\n",
       " '100',\n",
       " ',',\n",
       " '0',\n",
       " 'кг',\n",
       " '.',\n",
       " 'им',\n",
       " '##т',\n",
       " '34',\n",
       " ',',\n",
       " '60',\n",
       " 'кг',\n",
       " '/',\n",
       " 'м2',\n",
       " '.',\n",
       " 'температура',\n",
       " 'тела',\n",
       " ':',\n",
       " '36',\n",
       " ',',\n",
       " '6',\n",
       " '°',\n",
       " '##c',\n",
       " '.',\n",
       " 'правильно',\n",
       " 'ориентирована',\n",
       " 'в',\n",
       " 'пространстве',\n",
       " ',',\n",
       " 'собственно',\n",
       " '##и',\n",
       " 'личности',\n",
       " 'и',\n",
       " 'времени',\n",
       " ':',\n",
       " 'да',\n",
       " '.',\n",
       " 'питание',\n",
       " ':',\n",
       " 'повышенное',\n",
       " '.',\n",
       " 'катар',\n",
       " '##альные',\n",
       " 'явления',\n",
       " ':',\n",
       " 'нет',\n",
       " '.',\n",
       " 'кожа',\n",
       " ':',\n",
       " 'обычно',\n",
       " '##и',\n",
       " 'окраски',\n",
       " ',',\n",
       " 'влажная',\n",
       " '.',\n",
       " 'видимые',\n",
       " 'слизи',\n",
       " '##стые',\n",
       " 'нормально',\n",
       " '##и',\n",
       " 'окраски',\n",
       " '.',\n",
       " 'над',\n",
       " 'легкими',\n",
       " 'дыхание',\n",
       " ':',\n",
       " 'жесткое',\n",
       " '.',\n",
       " 'хрипы',\n",
       " ':',\n",
       " ',',\n",
       " 'единичные',\n",
       " 'рассеян',\n",
       " '##ные',\n",
       " 'сухие',\n",
       " 'хрипы',\n",
       " 'над',\n",
       " 'все',\n",
       " '##и',\n",
       " 'поверхностью',\n",
       " 'легких',\n",
       " ',',\n",
       " 'засто',\n",
       " '##ины',\n",
       " '##е',\n",
       " 'хрипы',\n",
       " 'в',\n",
       " 'н',\n",
       " '/',\n",
       " 'отделах',\n",
       " 'легких',\n",
       " '.',\n",
       " 'ч',\n",
       " '##дд',\n",
       " ':',\n",
       " '19',\n",
       " 'в',\n",
       " 'мин',\n",
       " ',',\n",
       " 'са',\n",
       " '##тура',\n",
       " '##ция',\n",
       " '96',\n",
       " '%',\n",
       " 'на',\n",
       " 'воздухе',\n",
       " 'в',\n",
       " 'покое',\n",
       " '.',\n",
       " 'органы',\n",
       " 'кровообращения',\n",
       " ':',\n",
       " 'пульс',\n",
       " ':',\n",
       " '78',\n",
       " 'в',\n",
       " 'мин',\n",
       " ',',\n",
       " 'ритми',\n",
       " '##чны',\n",
       " '##и',\n",
       " '.',\n",
       " 'ад',\n",
       " ',',\n",
       " 'мм',\n",
       " 'рт',\n",
       " '.',\n",
       " 'ст',\n",
       " '.',\n",
       " ':',\n",
       " '160',\n",
       " '/',\n",
       " '100',\n",
       " '.',\n",
       " 'органы',\n",
       " 'пищеварения',\n",
       " ':',\n",
       " 'живот',\n",
       " 'при',\n",
       " 'паль',\n",
       " '##па',\n",
       " '##ции',\n",
       " ':',\n",
       " 'мяг',\n",
       " '##кии',\n",
       " ',',\n",
       " 'не',\n",
       " 'взду',\n",
       " '##т',\n",
       " ',',\n",
       " 'участвует',\n",
       " 'в',\n",
       " 'акте',\n",
       " 'дыхания',\n",
       " ',',\n",
       " 'чувствительны',\n",
       " '##и',\n",
       " 'при',\n",
       " 'паль',\n",
       " '##па',\n",
       " '##ции',\n",
       " 'в',\n",
       " 'над',\n",
       " '##лоб',\n",
       " '##ково',\n",
       " '##и',\n",
       " 'области',\n",
       " '.',\n",
       " 'печень',\n",
       " ':',\n",
       " 'не',\n",
       " 'увеличена',\n",
       " '.',\n",
       " 'селез',\n",
       " '##енка',\n",
       " ':',\n",
       " 'не',\n",
       " 'увеличена',\n",
       " '.',\n",
       " 'симптомы',\n",
       " 'раздражения',\n",
       " 'брю',\n",
       " '##шины',\n",
       " ':',\n",
       " 'нет',\n",
       " '.',\n",
       " 'отек',\n",
       " '##и',\n",
       " ':',\n",
       " 'пасто',\n",
       " '##зно',\n",
       " '##сть',\n",
       " 'стоп',\n",
       " 'и',\n",
       " 'голе',\n",
       " '##не',\n",
       " '##и',\n",
       " '.',\n",
       " 'стул',\n",
       " ':',\n",
       " 'оформлен',\n",
       " '##ны',\n",
       " '##и',\n",
       " '(',\n",
       " 'был',\n",
       " 'сегодня',\n",
       " 'утром',\n",
       " ')',\n",
       " ',',\n",
       " 'газы',\n",
       " 'отходят',\n",
       " '.',\n",
       " 'патологи',\n",
       " '##ческие',\n",
       " 'примеси',\n",
       " 'в',\n",
       " 'кале',\n",
       " ':',\n",
       " 'нет',\n",
       " '.',\n",
       " 'симптом',\n",
       " 'поко',\n",
       " '##ла',\n",
       " '##чивания',\n",
       " 'отрица',\n",
       " '##тельны',\n",
       " '##и',\n",
       " 'с',\n",
       " 'обеих',\n",
       " 'сторон',\n",
       " '.',\n",
       " 'мочеиспуска',\n",
       " '##ние',\n",
       " ':',\n",
       " 'болезненное',\n",
       " ',',\n",
       " 'уча',\n",
       " '##щенное',\n",
       " ',',\n",
       " 'ди',\n",
       " '##уре',\n",
       " '##з',\n",
       " 'достаточ',\n",
       " '##ны',\n",
       " '##и',\n",
       " '(',\n",
       " 'со',\n",
       " 'слов',\n",
       " 'больно',\n",
       " '##и',\n",
       " ')',\n",
       " '.',\n",
       " 'гемогло',\n",
       " '##бин',\n",
       " '-',\n",
       " '124',\n",
       " ',',\n",
       " 'ле',\n",
       " '##ик',\n",
       " '##о',\n",
       " '##циты',\n",
       " '–',\n",
       " '7',\n",
       " '.',\n",
       " '8',\n",
       " ',',\n",
       " 'тром',\n",
       " '-',\n",
       " '138',\n",
       " '.',\n",
       " 'рент',\n",
       " 'ог',\n",
       " '##к',\n",
       " '-',\n",
       " 'очагов',\n",
       " '##ых',\n",
       " 'и',\n",
       " 'инф',\n",
       " '##иль',\n",
       " '##тра',\n",
       " '##тивных',\n",
       " 'изменении',\n",
       " 'нет',\n",
       " '.',\n",
       " 'усилен',\n",
       " 'лего',\n",
       " '##чны',\n",
       " '##и',\n",
       " 'рисунок',\n",
       " 'в',\n",
       " 'н',\n",
       " '/',\n",
       " 'о',\n",
       " '.',\n",
       " 'сердце',\n",
       " 'расширен',\n",
       " '##о',\n",
       " 'влево',\n",
       " '.',\n",
       " 'эк',\n",
       " '##г',\n",
       " '-',\n",
       " 'ритм',\n",
       " 'сину',\n",
       " '##совы',\n",
       " '##и',\n",
       " ',',\n",
       " 'п',\n",
       " '##б',\n",
       " '##п',\n",
       " '##н',\n",
       " '##пг',\n",
       " ',',\n",
       " 'и',\n",
       " '##шеми',\n",
       " '##ческих',\n",
       " 'изменении',\n",
       " 'не',\n",
       " 'выявлено',\n",
       " '.',\n",
       " 'к',\n",
       " '##т',\n",
       " 'головного',\n",
       " 'мозга',\n",
       " '-',\n",
       " 'остро',\n",
       " '##и',\n",
       " 'патологии',\n",
       " 'нет',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(tokens['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0][\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0, 7, 0, 0, 0, 7, 0, 0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0][\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'EU',\n",
       " 'rejects',\n",
       " 'German',\n",
       " 'call',\n",
       " 'to',\n",
       " 'boycott',\n",
       " 'British',\n",
       " 'la',\n",
       " '##mb',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)\n",
    "inputs.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'European',\n",
       " 'Commission',\n",
       " 'said',\n",
       " 'on',\n",
       " 'Thursday',\n",
       " 'it',\n",
       " 'disagreed',\n",
       " 'with',\n",
       " 'German',\n",
       " 'advice',\n",
       " 'to',\n",
       " 'consumers',\n",
       " 'to',\n",
       " 'shun',\n",
       " 'British',\n",
       " 'lamb',\n",
       " 'until',\n",
       " 'scientists',\n",
       " 'determine',\n",
       " 'whether',\n",
       " 'mad',\n",
       " 'cow',\n",
       " 'disease',\n",
       " 'can',\n",
       " 'be',\n",
       " 'transmitted',\n",
       " 'to',\n",
       " 'sheep',\n",
       " '.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][3][\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[-100, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "labels = raw_datasets[\"train\"][3][\"ner_tags\"]\n",
    "word_ids = inputs.word_ids()\n",
    "print(labels)\n",
    "print(align_labels_with_tokens(labels, word_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb99e146911c484c9b2bff85fac55fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2186bfeabe57484c8904efcef16bda97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f12db3974084ffbac92dcdf38fa25fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
