# AIm-Finder-2023

## Задача конкурса
Необходимо разработать информационную систему определения симптомов в медицинских эпикризах.

## Данные
100 размеченных эпикризов, 140 неразмеченных эпикризов

1 эпикриз ~ 500 слов, 10 симптомов

### Пример части эпикриза
Ранее туберкулезом не болел. <code style="color:orange"> Изменения в легких выявлены на КТ ОГК</code>, на которое был направлен после ДСТ. После <code style="color:orange"> выявления округлого образования в левом легком</code> был направлен к онкологу. По рекомендации онколога выполнил ПЭТ/КТ, после которой направлен на консультацию фтизиатра: рекомендовано оперативное вмешательство с целью морфологической верификации патологического процесса.: На основании данных анамнеза, клинико-рентгенологического  и лабораторного обследования установлен диагноз: Основной: Объемное образование верхней доли левого легкого: Туберкулома? Гамартохондрома? Показана морфологическая верификация процесса в легких. Перевод в ЛХО после завершения обследования.

## Подход к решению
1. Сделать доразметку
2. Обучить языковую модель классифицировать токены (Named Entity Recognition)
3. Сделать постобработку.

### 1. Доразметка 
Был развернут сервис [label-studio](https://labelstud.io/), 3 практикующих врача разметили 140 эпикризов.
Данные выделены в [обучающий](https://huggingface.co/datasets/kosta-naumenko/medflex) и [тестовый](https://huggingface.co/datasets/kosta-naumenko/medflex-test) наборы.

### 2. Обучение нейросети
В основу экспериментов положен [туториал по NER](https://huggingface.co/learn/nlp-course/chapter7/2), логирование осуществлялось в [mlflow](https://mlflow.org/).
Были проведены эксперименты по дообучению языковой модели [RuBioRoBERTa](https://huggingface.co/alexyalunin/RuBioRoBERTa).

1)  Дообучение [классификатора](/notebooks/experiments/RuBio_finetune.ipynb) 

2)  Дообучение модели с помощью [LoRA](/notebooks/experiments/Lora_finetune.ipynb) 

3) Дообучение модели c помощью LoRA на задаче [MLM](/notebooks/experiments/Lora_MLM.ipynb), а затем на задаче [классификации](/notebooks/experiments/Lora_finetune_from_MLM.ipynb). Для MLM был надйен другой датасет с анаимнезами заболеваний ~ 14 000 примеров.

### 3. Постобработка
Выход модели может содержать части слов, ненужные символы или явно неправильные примеры, поэтому постобработка содержит множество эвристик, которые были придуманы в конце конкурса.


## Вывод



